{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "MAML_Omniglot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gunaranjan66/Machine-Learning/blob/master/MAML_Omniglot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euZcI0Y9e1PC",
        "colab_type": "text"
      },
      "source": [
        "# Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDmRho1me1PO",
        "colab_type": "text"
      },
      "source": [
        "   ___Intorduction___:  Artificial intelligence is trying to learn how to learn from the way humans learn. We can quickly and easily recognize a new object from just seeing one or few pictures of it, or even from only reading about it without having ever seen it before. We can learn quickly a new skill as well as master many different tasks. This seems easy for the human intelligence but for machines, it is quite a challenge to overcome. Berkeley AI Research Lab published a research paper introducing Model-Agnostic Meta-learning MAML which is a simple solution, yet so powerful and game-changing in meta-learning (or learning to learn)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKc87UM8e1PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#packages\n",
        "import pandas as pd #data analysis\n",
        "import torch       #Deep network model designer\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from PIL import Image # Image processing\n",
        "import torchvision.transforms as transforms #transformations\n",
        "import torch.nn as nn #Nework layers\n",
        "from collections import OrderedDict #creating dictionaries\n",
        "import torch.nn.functional as F \n",
        "import random\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYkf8PMte1P1",
        "colab_type": "text"
      },
      "source": [
        "# Downloading the data (omniglot)\n",
        "\n",
        "Omniglot data set for one-shot learning. This dataset contains 1623 different handwritten characters from 50 different alphabets.<br/>\n",
        "<li>This dataset is prepocessed and normalized</li>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P55mS5lie1P7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_url(url, save_path):\n",
        "    '''Args:\n",
        "            url : path to download file\n",
        "            save_path : file path to save to give url'''\n",
        "    with urllib.request.urlopen(url) as dl_file:\n",
        "        with open(save_path, 'wb') as out_file:\n",
        "            out_file.write(dl_file.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YebFb4Me1QY",
        "colab_type": "code",
        "outputId": "a42ffbd6-38c4-44fe-b35a-61037e15b299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "directory=\"data\"\n",
        "if not os.path.isdir(directory):\n",
        "    os.mkdir(directory)\n",
        "\n",
        "\n",
        "#urls for data\n",
        "urls = [\n",
        "        'https://github.com/brendenlake/omniglot/raw/master/python/images_background.zip',\n",
        "        'https://github.com/brendenlake/omniglot/raw/master/python/images_evaluation.zip'\n",
        "    ]\n",
        "\n",
        "\n",
        "for url in urls:\n",
        "    filename = url.split('/')[-1]\n",
        "    file_path = os.path.join(directory, filename)\n",
        "    print('== Downloading ' + filename)\n",
        "    download_url(url,file_path)\n",
        "    print(\"== Unzip from \" + file_path + \" to \" + directory)\n",
        "    zip_ref = zipfile.ZipFile(file_path, 'r')\n",
        "    zip_ref.extractall(directory)\n",
        "    zip_ref.close()\n",
        "print(\"Completed Downloading\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "== Downloading images_background.zip\n",
            "== Unzip from data/images_background.zip to data\n",
            "== Downloading images_evaluation.zip\n",
            "== Unzip from data/images_evaluation.zip to data\n",
            "Completed Downloading\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3nFaIgee1Qz",
        "colab_type": "text"
      },
      "source": [
        "## Labeling the data save it into csv file for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM84qJKve1Q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def labeling(folder,result_name):\n",
        "    global assigned_label\n",
        "    with open(result_name,'w') as csvfile:\n",
        "        fields=['ID','Path','Label']\n",
        "        csvwriter=csv.writer(csvfile,delimiter=',')\n",
        "        csvwriter.writerow(fields)\n",
        "        for a in os.listdir(folder):\n",
        "            i=0\n",
        "            for charfolder in os.listdir(folder+'/'+a):\n",
        "                for image in os.listdir(folder+'/'+a+'/'+charfolder):\n",
        "                    label=assigned_label\n",
        "                    path=folder+'/'+a+'/'+charfolder+'/'+image\n",
        "                    csvwriter.writerow([image,path,str(label)])\n",
        "                assigned_label+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iVs0lyBe1RL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assigned_label=0\n",
        "train_root='data/images_background'\n",
        "test_root='data/images_evaluation'\n",
        "labeling(train_root,\"train.csv\")\n",
        "labeling(test_root,\"test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_K2DgsVzc7Z",
        "colab_type": "text"
      },
      "source": [
        "Reading data from file which is created by above cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRP3lVjZe1RX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data=pd.read_csv(\"train.csv\")\n",
        "test_data=pd.read_csv(\"test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9X4rheHl1y59",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1915d30f-27f4-4487-d928-dc3baf1f075d"
      },
      "source": [
        "train_data.sample(5)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Path</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5936</th>\n",
              "      <td>0413_13.png</td>\n",
              "      <td>data/images_background/Greek/character20/0413_...</td>\n",
              "      <td>296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19128</th>\n",
              "      <td>0480_18.png</td>\n",
              "      <td>data/images_background/Hebrew/character15/0480...</td>\n",
              "      <td>956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4614</th>\n",
              "      <td>0940_08.png</td>\n",
              "      <td>data/images_background/Tifinagh/character31/09...</td>\n",
              "      <td>230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1170</th>\n",
              "      <td>0875_18.png</td>\n",
              "      <td>data/images_background/Sanskrit/character25/08...</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7205</th>\n",
              "      <td>0278_01.png</td>\n",
              "      <td>data/images_background/Syriac_(Estrangelo)/cha...</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                ID                                               Path  Label\n",
              "5936   0413_13.png  data/images_background/Greek/character20/0413_...    296\n",
              "19128  0480_18.png  data/images_background/Hebrew/character15/0480...    956\n",
              "4614   0940_08.png  data/images_background/Tifinagh/character31/09...    230\n",
              "1170   0875_18.png  data/images_background/Sanskrit/character25/08...     58\n",
              "7205   0278_01.png  data/images_background/Syriac_(Estrangelo)/cha...    360"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eftGFUc1e1Wh",
        "colab_type": "code",
        "outputId": "199aa6e9-3e54-4aa6-ef12-33d5cc9c3651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qebC_bgMzn-X",
        "colab_type": "text"
      },
      "source": [
        "# Pre step for input the data into model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3icEL-hge1Wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MiniSet(Dataset):\n",
        "    def __init__(self,fileroots,labels,transform):\n",
        "      '''\n",
        "      Args:\n",
        "          fileroots:path of image file\n",
        "          labels:output label to the fileroot image\n",
        "          transform:transform applied on images\n",
        "      '''\n",
        "        self.fileroots=fileroots\n",
        "        self.labels=labels\n",
        "        self.transform=transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fileroots)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        img=Image.open(self.fileroots[idx])\n",
        "        img=self.transform(img)\n",
        "        return img,self.labels[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIOJMmGae1XL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Task(object):\n",
        "    def __init__(self,data,all_classes,num_classes,k_way,k_query,transforms):\n",
        "      '''\n",
        "        Args:\n",
        "          data:pandas data frame that use for create task form it\n",
        "          all_classes:Array of classes of output of data\n",
        "          num_classes:Num classes is required for each task\n",
        "          k_way:num for samples of each class for inner step\n",
        "          k_query:num of sample for outer step update\n",
        "          transform:transform applied on images\n",
        "      '''\n",
        "        self.all_classes=all_classes\n",
        "        self.num_classes=num_classes\n",
        "        self.train_roots=[]\n",
        "        self.meta_roots=[]\n",
        "        self.train_labels=[]\n",
        "        self.meta_labels=[]\n",
        "        samples_per_class=20\n",
        "        self.transforms=transforms\n",
        "        sampled_classes=random.sample(all_classes,num_classes)\n",
        "        label=0\n",
        "        val=int(data.iloc[0][\"Label\"])\n",
        "        for c in sampled_classes:\n",
        "            cframe=data.iloc[((c-val)*samples_per_class):(((c+1)-val)*samples_per_class)]\n",
        "            cframe.reset_index(inplace=True,drop=True)\n",
        "            paths=cframe[\"Path\"]\n",
        "            sample_idxs=np.random.choice(samples_per_class,samples_per_class,replace=False)\n",
        "            train_idxs=sample_idxs[:k_way]\n",
        "            meta_idxs=sample_idxs[k_way:(k_way+k_query)]\n",
        "            for idx in train_idxs:\n",
        "                self.train_roots.append(paths[idx])\n",
        "                self.train_labels.append(label)\n",
        "            for idx in meta_idxs:\n",
        "                self.meta_roots.append(paths[idx])\n",
        "                self.meta_labels.append(label)\n",
        "            label+=1\n",
        "    def get_loaders(self):\n",
        "        loaders={}\n",
        "        trainloader=DataLoader(MiniSet(self.train_roots,self.train_labels,self.transforms),\n",
        "                             batch_size=len(self.train_roots),shuffle=True)\n",
        "        testloader=DataLoader(MiniSet(self.meta_roots,self.meta_labels,self.transforms),\n",
        "                             batch_size=len(self.meta_roots),shuffle=True)\n",
        "        loaders[\"sample\"]=trainloader\n",
        "        loaders[\"query\"]=testloader\n",
        "        return loaders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scV4_f8Ke1Xc",
        "colab_type": "text"
      },
      "source": [
        "## creating Model\n",
        "![alt text](https://miro.medium.com/max/3744/1*SGPGG7oeSvVlV5sOSQ2iZw.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q_7y9wLe1Xg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaseNet(nn.Module):\n",
        "    def __init__(self,num_classes):\n",
        "        super(BaseNet,self).__init__()\n",
        "        '''Args:\n",
        "                num_classed : number of output labels\n",
        "            '''\n",
        "        self.features = nn.Sequential(OrderedDict([  \n",
        "                    ('conv1', nn.Conv2d(1, 64, 3)),  # 64x26x26\n",
        "                    ('bn1', nn.BatchNorm2d(64, momentum=1, affine=True)),\n",
        "                    ('relu1', nn.ReLU(inplace=True)),\n",
        "                    ('pool1', nn.MaxPool2d(2,2)), #    64x13x13\n",
        "                    ('conv2', nn.Conv2d(64,64,3)),  #  64x11x11\n",
        "                    ('bn2', nn.BatchNorm2d(64, momentum=1, affine=True)),\n",
        "                    ('relu2', nn.ReLU(inplace=True)),\n",
        "                    ('pool2', nn.MaxPool2d(2,2)), #    64x5x5\n",
        "                    ('conv3', nn.Conv2d(64,64,3)), #   64x3x3\n",
        "                    ('bn3', nn.BatchNorm2d(64, momentum=1, affine=True)),\n",
        "                    ('relu3', nn.ReLU(inplace=True)),\n",
        "                    ('pool3', nn.MaxPool2d(2,2))]))  #64x1x1  \n",
        "        self.fc= nn.Linear(64,num_classes) \n",
        "\n",
        "    def forward(self,x,weights=None):\n",
        "        '''Args:\n",
        "                x:input images (n x c x 28 x 28 size images)\n",
        "                n:number of images\n",
        "                c:number of color channels\n",
        "            returns:\n",
        "                    (n x num_classes) dimenstion array '''\n",
        "        if weights==None:  \n",
        "            output=self.features(x)\n",
        "            output=output.view(-1,64)\n",
        "            output=self.fc(output)\n",
        "        else:\n",
        "            x = F.conv2d(x, weights['features.conv1.weight'], weights['features.conv1.bias'])\n",
        "            x = F.batch_norm(x, weights['features.bn1.running_mean'], \n",
        "                             weights['features.bn1.running_var'],\n",
        "                              weights['features.bn1.weight'],\n",
        "                             weights['features.bn1.bias'],momentum=1,training=True)\n",
        "            x = F.relu(x)\n",
        "            x = F.max_pool2d(x, kernel_size=2, stride=2) \n",
        "            x = F.conv2d(x, weights['features.conv2.weight'], weights['features.conv2.bias'])\n",
        "            x = F.batch_norm(x, weights['features.bn2.running_mean'], \n",
        "                             weights['features.bn2.running_var'],\n",
        "                              weights['features.bn2.weight'],\n",
        "                             weights['features.bn2.bias'],momentum=1,training=True)\n",
        "            x = F.relu(x)\n",
        "            x = F.max_pool2d(x, kernel_size=2, stride=2) \n",
        "            x = F.conv2d(x, weights['features.conv3.weight'], weights['features.conv3.bias'])\n",
        "            x = F.batch_norm(x, weights['features.bn3.running_mean'], \n",
        "                             weights['features.bn3.running_var'],\n",
        "                              weights['features.bn3.weight'],\n",
        "                             weights['features.bn3.bias'],momentum=1,training=True)\n",
        "            x = F.relu(x)\n",
        "            x = F.max_pool2d(x, kernel_size=2, stride=2) \n",
        "            x = x.view(x.size(0), 64)\n",
        "            output = F.linear(x, weights['fc.weight'], weights['fc.bias'])\n",
        "        out = F.log_softmax(output, dim=1)\n",
        "        return out\n",
        "    def get_weights(self):\n",
        "        model_weights = {key: val.clone() for key, val in self.state_dict().items()}\n",
        "        return model_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhHaV8M2z2j5",
        "colab_type": "text"
      },
      "source": [
        "# Inner_loop for MAML model\n",
        "![alt text](https://image.slidesharecdn.com/maml-181130144044/95/introduction-to-maml-model-agnostic-meta-learning-with-discussions-19-638.jpg?cb=1543588892)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMM73sYJe1Xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_single_task(net,lr,loaders,num_updates,loss_metric):\n",
        "  '''\n",
        "    Args:\n",
        "      net:Model that used\n",
        "      loaders:Data for inputing into model\n",
        "      lr:learning rate for inner loop\n",
        "      num_updates:number of time does inner loop get update the weights\n",
        "      loss_metric:loss function\n",
        "  '''\n",
        "    net.train()\n",
        "    trainloader=loaders[\"sample\"]\n",
        "    x,y=trainloader.__iter__().next()\n",
        "    x.to(device)\n",
        "    y.to(device)\n",
        "    output=net(x)\n",
        "    loss=loss_metric(output,y)\n",
        "    def zero_grad(params):\n",
        "        for p in params:\n",
        "            if p.grad is not None:\n",
        "                p.grad.zero_()\n",
        "    zero_grad(net.parameters())\n",
        "    grads=torch.autograd.grad(loss,net.parameters(),create_graph=True)\n",
        "    mod_state_dict=net.get_weights()\n",
        "    mod_weights=OrderedDict()\n",
        "    for (k,v),g in zip(net.named_parameters(),grads):\n",
        "        mod_weights[k]=v-lr*g\n",
        "        mod_state_dict[k]=mod_weights[k]\n",
        "    for i in range(1,num_updates):\n",
        "        output=net(x,mod_state_dict)\n",
        "        loss=loss_metric(output,y)\n",
        "        zero_grad(mod_weights.values())\n",
        "        grads=torch.autograd.grad(loss,mod_weights.values(),create_graph=True)\n",
        "        for (k,v),g in zip(mod_weights.items(),grads):\n",
        "            mod_weights[k]=v-lr*g\n",
        "            mod_state_dict[k]=mod_weights[k]\n",
        "    return mod_state_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fT5nlnXz8vC",
        "colab_type": "text"
      },
      "source": [
        "# Traing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR0xtR0Je1X5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net,meta_train_classes,meta_optimiser,loss_metric,transforms,num_classes,\n",
        "          k_way,k_query,num_tasks,lr,meta_lr,num_inner_updates,num_epochs):   \n",
        "  '''\n",
        "    Args:\n",
        "      net:Model\n",
        "      meta_train_classes:Total class in the data\n",
        "      meta_optimiser:optimizer for outer loop\n",
        "      loss_metric:Loss function\n",
        "      transforms:transforms applied on data\n",
        "      num_classes:Number of classes on each task\n",
        "      k_way:number of images on each class for each task for inner loop\n",
        "      k_query:number of images on each class for each task for outer loop\n",
        "      lr:learning rate for inner loop\n",
        "      meta_lr:learning rate for meta update(outer loop)\n",
        "      num_inner_updates:number of time does inner loop get update the weights\n",
        "  '''\n",
        "    total_loss=0\n",
        "    meta_losses=[]\n",
        "    for epoch in range(1,num_epochs+1):\n",
        "        state_dicts=[]\n",
        "        loaders_list=[]\n",
        "        for n in range(num_tasks):\n",
        "            task=Task(train_data,meta_train_classes,num_classes,k_way,k_query,transforms)\n",
        "            loaders=task.get_loaders()\n",
        "            d=train_single_task(net,lr,loaders,num_inner_updates,loss_metric)\n",
        "            state_dicts.append(d)\n",
        "            loaders_list.append(loaders)\n",
        "        metaloss=0\n",
        "        for n in range(num_tasks):\n",
        "            loaders=loaders_list[n]\n",
        "            metaloader=loaders[\"query\"]\n",
        "            x,y=metaloader.__iter__().next()\n",
        "            x.to(device)\n",
        "            y.to(device)\n",
        "            d=state_dicts[n]\n",
        "            output=net(x,d)\n",
        "            loss=loss_metric(output,y)\n",
        "            metaloss+=loss\n",
        "        metaloss/=float(num_tasks)\n",
        "        total_loss+=metaloss.item()\n",
        "        meta_optimiser.zero_grad()\n",
        "        metaloss.backward()\n",
        "        meta_optimiser.step()\n",
        "        if (epoch % 10) == 0:\n",
        "            print(\"{}/{}. loss: {}\".format(epoch, num_epochs, total_loss / 2))\n",
        "        if (epoch%2)==0:\n",
        "            meta_losses.append(total_loss/2)\n",
        "            total_loss = 0\n",
        "    return meta_losses,net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki_AWPfme1YE",
        "colab_type": "code",
        "outputId": "5330ec8d-6e48-41db-8482-b8995816635f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "loss_metric=nn.NLLLoss()\n",
        "num_classes=5\n",
        "net=BaseNet(num_classes)\n",
        "lr=1e-1\n",
        "meta_lr=1e-3\n",
        "meta_optimizer = torch.optim.Adam(net.parameters(), lr=meta_lr)\n",
        "k_way=10\n",
        "k_query=10\n",
        "num_tasks=10\n",
        "num_inner_updates=1\n",
        "num_epochs=100\n",
        "train_classes=np.max(train_data['Label'])\n",
        "train_classes=list(np.arange(train_classes))\n",
        "transform=transforms.Compose([transforms.Resize((28,28)),transforms.ToTensor()])\n",
        "metalosses,net=train(net,train_classes,meta_optimizer,loss_metric,transform,\n",
        "                     num_classes,k_way,k_query,num_tasks,lr,meta_lr,\n",
        "                     num_inner_updates,num_epochs)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/100. loss: 0.6642213463783264\n",
            "20/100. loss: 0.510557621717453\n",
            "30/100. loss: 0.3551229238510132\n",
            "40/100. loss: 0.3085741251707077\n",
            "50/100. loss: 0.28945405781269073\n",
            "60/100. loss: 0.24506106972694397\n",
            "70/100. loss: 0.21089977771043777\n",
            "80/100. loss: 0.20205962657928467\n",
            "90/100. loss: 0.20156239718198776\n",
            "100/100. loss: 0.18115905672311783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N6w_1rTe1Yo",
        "colab_type": "code",
        "outputId": "e100f35e-062b-4d3e-dcdd-3dc5bac98ee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(metalosses,color='b')\n",
        "plt.title(\"Loss function\")\n",
        "plt.xlabel(\"Epoches\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTx7XhgTyZR-",
        "colab_type": "text"
      },
      "source": [
        "<h1>Evaluation on test_data</h1><br/>\n",
        "<p>Taking sample's form the test data and perform the MAML on the sample "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yEN-Nse4nW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "  outputs = np.argmax(outputs, axis=1)\n",
        "  return np.sum(outputs == labels) / float(labels.size)\n",
        "def evaluate(net,test_classes,task_lr,transform,num_classes=3,num_steps=100,k_way=3,k_query=5,num_eval_updates=5):\n",
        "    losses=[]\n",
        "    acc_list=[]\n",
        "    for step in np.arange(num_steps):\n",
        "        task=Task(test_data,test_classes,num_classes=num_classes,k_way=k_way,k_query=k_query,transforms=transform)\n",
        "        loaders=task.get_loaders()\n",
        "        trainloader,testloader=loaders[\"sample\"],loaders[\"query\"]\n",
        "        x_train,y_train=trainloader.__iter__().next()\n",
        "        x_test,y_test=testloader.__iter__().next()\n",
        "        x_train.to(device)\n",
        "        y_train.to(device)\n",
        "        x_test.to(device)\n",
        "        y_test.to(device)\n",
        "        cloned_net=copy.deepcopy(net)\n",
        "        optim = torch.optim.SGD(cloned_net.parameters(),lr=task_lr)\n",
        "        for _ in range(num_eval_updates):\n",
        "            y_train_pred=cloned_net(x_train)\n",
        "            loss=loss_metric(y_train_pred,y_train)\n",
        "            optim.zero_grad()\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "        y_test_pred=cloned_net(x_test)\n",
        "        loss=loss_metric(y_test_pred,y_test)\n",
        "        losses.append(loss)\n",
        "        y_test_pred=y_test_pred.data.cpu().numpy()\n",
        "        y_test=y_test.data.cpu().numpy()\n",
        "        acc=accuracy(y_test_pred,y_test)\n",
        "        if step%10==0:\n",
        "          print(\"accuracy is: \",acc)\n",
        "        acc_list.append(acc)\n",
        "    return acc_list,losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_LizSen4-A2",
        "colab_type": "code",
        "outputId": "ac4b55b5-1487-4d4c-f714-3fae2186fecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import copy\n",
        "#test_classes=np.max(testframe['Label'])-np.min(testframe['Label'])\n",
        "test_classes=list(np.arange(np.min(test_data['Label']),np.max(test_data['Label']+1)))\n",
        "acc_list,losses=evaluate(net,test_classes,task_lr=1e-1,transform=transform,k_way=k_way,k_query=k_query )"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy is:  0.9666666666666667\n",
            "accuracy is:  1.0\n",
            "accuracy is:  1.0\n",
            "accuracy is:  0.9\n",
            "accuracy is:  1.0\n",
            "accuracy is:  1.0\n",
            "accuracy is:  0.9666666666666667\n",
            "accuracy is:  1.0\n",
            "accuracy is:  1.0\n",
            "accuracy is:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU_A98J43TOm",
        "colab_type": "text"
      },
      "source": [
        "From the above output it predicts better event though training sample are less"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LRnVsDB3R5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJQiEXsGzM9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}